{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from io import StringIO\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv(\"C:/Users/erknud3/fpl-optimization/model/FPL-ID-MAP/master.csv\")\n",
    "master = master[['code','first_name', 'second_name', 'web_name', 'fbref', 'transfermarkt', '24-25']]\n",
    "master = master.dropna(subset=['fbref', '24-25'])\n",
    "\n",
    "\n",
    "master['fbref'] = master['fbref'].astype(str)\n",
    "master['transfermarkt'] = master['transfermarkt'].fillna(0).astype(int)\n",
    "master['24-25'] = master['24-25'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>first_name</th>\n",
       "      <th>second_name</th>\n",
       "      <th>web_name</th>\n",
       "      <th>fbref</th>\n",
       "      <th>transfermarkt</th>\n",
       "      <th>24-25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>438098</td>\n",
       "      <td>Fábio</td>\n",
       "      <td>Ferreira Vieira</td>\n",
       "      <td>Fábio Vieira</td>\n",
       "      <td>6412cc03</td>\n",
       "      <td>537598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>205651</td>\n",
       "      <td>Gabriel</td>\n",
       "      <td>Fernando de Jesus</td>\n",
       "      <td>G.Jesus</td>\n",
       "      <td>b66315ae</td>\n",
       "      <td>363205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>226597</td>\n",
       "      <td>Gabriel</td>\n",
       "      <td>dos Santos Magalhães</td>\n",
       "      <td>Gabriel</td>\n",
       "      <td>67ac5bb8</td>\n",
       "      <td>435338</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>219847</td>\n",
       "      <td>Kai</td>\n",
       "      <td>Havertz</td>\n",
       "      <td>Havertz</td>\n",
       "      <td>fed7cb61</td>\n",
       "      <td>309400</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>463748</td>\n",
       "      <td>Karl</td>\n",
       "      <td>Hein</td>\n",
       "      <td>Hein</td>\n",
       "      <td>aa81d8f8</td>\n",
       "      <td>493513</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>518438</td>\n",
       "      <td>Kaelan</td>\n",
       "      <td>Casey</td>\n",
       "      <td>Casey</td>\n",
       "      <td>cd4b2c5f</td>\n",
       "      <td>845321</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>574398</td>\n",
       "      <td>Franco</td>\n",
       "      <td>Umeh-Chibueze</td>\n",
       "      <td>Umeh-Chibueze</td>\n",
       "      <td>8e526344</td>\n",
       "      <td>943560</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>530318</td>\n",
       "      <td>Kaden</td>\n",
       "      <td>Rodney</td>\n",
       "      <td>Rodney</td>\n",
       "      <td>49375cdd</td>\n",
       "      <td>860078</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>575034</td>\n",
       "      <td>Ethan</td>\n",
       "      <td>Wheatley</td>\n",
       "      <td>Wheatley</td>\n",
       "      <td>5c368c88</td>\n",
       "      <td>888639</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>179519</td>\n",
       "      <td>Orel</td>\n",
       "      <td>Mangala</td>\n",
       "      <td>Mangala</td>\n",
       "      <td>a572e291</td>\n",
       "      <td>289592</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>715 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        code first_name           second_name       web_name     fbref  \\\n",
       "1784  438098      Fábio       Ferreira Vieira   Fábio Vieira  6412cc03   \n",
       "1315  205651    Gabriel     Fernando de Jesus        G.Jesus  b66315ae   \n",
       "1525  226597    Gabriel  dos Santos Magalhães        Gabriel  67ac5bb8   \n",
       "1439  219847        Kai               Havertz        Havertz  fed7cb61   \n",
       "1966  463748       Karl                  Hein           Hein  aa81d8f8   \n",
       "...      ...        ...                   ...            ...       ...   \n",
       "2287  518438     Kaelan                 Casey          Casey  cd4b2c5f   \n",
       "2420  574398     Franco         Umeh-Chibueze  Umeh-Chibueze  8e526344   \n",
       "2311  530318      Kaden                Rodney         Rodney  49375cdd   \n",
       "2422  575034      Ethan              Wheatley       Wheatley  5c368c88   \n",
       "1147  179519       Orel               Mangala        Mangala  a572e291   \n",
       "\n",
       "      transfermarkt  24-25  \n",
       "1784         537598      1  \n",
       "1315         363205      2  \n",
       "1525         435338      3  \n",
       "1439         309400      4  \n",
       "1966         493513      5  \n",
       "...             ...    ...  \n",
       "2287         845321    643  \n",
       "2420         943560    644  \n",
       "2311         860078    647  \n",
       "2422         888639    648  \n",
       "1147         289592    651  \n",
       "\n",
       "[715 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.sort_values(by='24-25', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master['fbref'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = master['fbref'].unique()\n",
    "seasons = ['2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
    "\n",
    "fbref_urls = []\n",
    "\n",
    "for fbref in unique_ids:\n",
    "    for season in seasons:\n",
    "        url = f\"https://fbref.com/en/players/{fbref}/matchlogs/{season}/\"\n",
    "        fbref_urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:   0%|          | 0/2560 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process URL: https://fbref.com/en/players/2f90f6b8/matchlogs/2021-2022/. Error: 429 Client Error: Too Many Requests for url: https://fbref.com/en/players/2f90f6b8/matchlogs/2021-2022/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:   0%|          | 0/2560 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m     failed_urls\u001b[38;5;241m.\u001b[39mappend(url)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to process URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Update the progress bar\u001b[39;00m\n\u001b[0;32m     41\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lists to track successful and failed URLs\n",
    "successful_urls = []\n",
    "failed_urls = []\n",
    "\n",
    "# Folder to save HTML files\n",
    "output_folder = \"C:/Users/erknud3/fpl-optimization/model/html_files/matchlogs_players\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through URLs with progress bar\n",
    "with tqdm(total=len(fbref_urls), desc=\"Processing URLs\") as pbar:\n",
    "    for url in fbref_urls:\n",
    "        try:\n",
    "            # Extract fbref ID and season for naming the file\n",
    "            parts = url.split('/')\n",
    "            fbref_id = parts[5]\n",
    "            season = parts[7]\n",
    "\n",
    "            # Send a request to fetch the HTML content\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "\n",
    "            # Create a filename based on fbref ID and season\n",
    "            filename = f\"{fbref_id}_matchlogs_{season}.txt\"\n",
    "            file_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Save the HTML content to the file\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(response.text)\n",
    "\n",
    "            # Append to successful_urls\n",
    "            successful_urls.append(url)\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            # Append to failed_urls in case of an error\n",
    "            failed_urls.append(url)\n",
    "            print(f\"Failed to process URL: {url}. Error: {e}\")\n",
    "            \n",
    "        time.sleep(6)\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "# Save failed URLs for future reference\n",
    "if failed_urls:\n",
    "    with open(os.path.join(output_folder, 'failed_urls.txt'), 'w') as f:\n",
    "        for url in failed_urls:\n",
    "            f.write(url + '\\n')\n",
    "\n",
    "# Save successful URLs for future reference\n",
    "if successful_urls:\n",
    "    with open(os.path.join(output_folder, 'successful_urls.txt'), 'w') as f:\n",
    "        for url in successful_urls:\n",
    "            f.write(url + '\\n')\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the saved URLs and HTML files\n",
    "output_folder = \"C:/Users/erknud3/fpl-optimization/model/html_files/matchlogs_players\"\n",
    "\n",
    "# Load the failed URLs from the previous run\n",
    "failed_urls = []\n",
    "failed_urls_path = os.path.join(output_folder, 'failed_urls.txt')\n",
    "if os.path.exists(failed_urls_path):\n",
    "    with open(failed_urls_path, 'r') as f:\n",
    "        failed_urls = [line.strip() for line in f]\n",
    "\n",
    "# Lists to track the new successful and failed URLs\n",
    "successful_urls_retry = []\n",
    "failed_urls_retry = []\n",
    "\n",
    "# Retry the process for failed URLs\n",
    "with tqdm(total=len(failed_urls), desc=\"Retrying Failed URLs\") as pbar:\n",
    "    for url in failed_urls:\n",
    "        try:\n",
    "            # Extract fbref ID and season for naming the file\n",
    "            parts = url.split('/')\n",
    "            fbref_id = parts[5]\n",
    "            season = parts[7]\n",
    "\n",
    "            # Send a request to fetch the HTML content\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "\n",
    "            # Create a filename based on fbref ID and season\n",
    "            filename = f\"{fbref_id}_matchlogs_{season}.txt\"\n",
    "            file_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Save the HTML content to the file\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(response.text)\n",
    "\n",
    "            # Append to successful_urls_retry\n",
    "            successful_urls_retry.append(url)\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            # Append to failed_urls_retry in case of an error\n",
    "            failed_urls_retry.append(url)\n",
    "            print(f\"Failed to process URL: {url}. Error: {e}\")\n",
    "            \n",
    "        time.sleep(6)\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "# Save the new failed URLs for future reference\n",
    "if failed_urls_retry:\n",
    "    with open(os.path.join(output_folder, 'failed_urls_retry.txt'), 'w') as f:\n",
    "        for url in failed_urls_retry:\n",
    "            f.write(url + '\\n')\n",
    "\n",
    "# Save the new successful URLs for reference\n",
    "if successful_urls_retry:\n",
    "    with open(os.path.join(output_folder, 'successful_urls_retry.txt'), 'w') as f:\n",
    "        for url in successful_urls_retry:\n",
    "            f.write(url + '\\n')\n",
    "\n",
    "print(\"Retry processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36 Edg/128.0.0.0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "with tqdm(total=len(fbref_urls), desc=\"Processing URLs\") as pbar:\n",
    "    for url in fbref_urls:\n",
    "        try:\n",
    "            with requests.Session() as session:\n",
    "                data = session.get(url, headers=headers)\n",
    "                soup = BeautifulSoup(data.text, \"html.parser\")\n",
    "                ids = re.search(r\"/players/([a-zA-Z0-9]{8})/\", url)\n",
    "                season = re.search(r\"/(\\d{4}-\\d{4})/\", url)\n",
    "                squad_id = table.find_all(\"td\", {\"data-stat\": \"team\"})[0].find('a')['href'].split('/en/squads/')[1].split('/')[0]\n",
    "\n",
    "                table = soup.find(\"table\", {\"id\": \"matchlogs_all\"})\n",
    "\n",
    "                df = pd.read_html(StringIO(str(table)))[0]\n",
    "                df.columns = [\n",
    "                    f\"{i} {j}\" if \"Unnamed\" not in i else j for i, j in df.columns\n",
    "                ]\n",
    "                \n",
    "                df[\"fbref\"] = ids.group(1)\n",
    "                df[\"season\"] = season.group(1)\n",
    "                df[\"squad_id\"] = squad_id\n",
    "                \n",
    "                all_dfs.append(df)\n",
    "                \n",
    "                time.sleep(6)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for URL: {url}: {e}\")\n",
    "\n",
    "        pbar.update(1)\n",
    "        #print(f\"Status code: {data.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_logs = pd.concat(all_dfs)\n",
    "\n",
    "match_logs = match_logs.rename ({\n",
    "    \"Performance Gls\": \"Goals\", \"Performance Ast\": \"Assists\", \"Performance PK\": \"PKs\", \"Performance PKatt\": \"PKatt\", \"Performance CrdY\": \"CrdY\", \"Performance CrdR\": \"CrdR\", \"Expected xG\": \"xG\", \"Expected npxG\": \"npxG\", \"Expected xAG\": \"xAG\",\n",
    "    }, axis=1)\n",
    "match_logs.dropna(inplace=True)\n",
    "match_logs = match_logs.merge(master[['fbref', 'transfermarkt', '24-25', 'first_name', 'second_name', 'web_name']], on='fbref', how='inner')\n",
    "match_logs = match_logs.rename({'24-25': 'fpl_id'}, axis=1)\n",
    "match_logs.columns = match_logs.columns.str.lower()\n",
    "match_logs = match_logs[['date', 'fbref', 'transfermarkt', 'fpl_id', 'first_name', 'second_name', 'web_name', 'season', 'comp', 'round', 'venue', 'squad_id', 'squad', 'opponent', 'start', 'min', 'goals', 'assists', 'pks', 'pkatt', 'xg', 'npxg', 'xag']]\n",
    "match_logs[['min', 'goals', 'assists', 'pks', 'pkatt', 'xg', 'npxg', 'xag']] = match_logs[['min', 'goals', 'assists', 'pks', 'pkatt', 'xg', 'npxg', 'xag']].replace(\"On matchday squad, but did not play\", 0)\n",
    "match_logs['squad'] = match_logs['squad'].str.replace(r'\\b[a-z]+\\b', '', regex=True).str.strip()\n",
    "match_logs['opponent'] = match_logs['opponent'].str.replace(r'\\b[a-z]+\\b', '', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_squad_ids = match_logs['squad_id'].unique()\n",
    "unique_squad_names = match_logs['squad'].unique()\n",
    "seasons = ['2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
    "\n",
    "squad_urls = []\n",
    "\n",
    "for squad_id, squad_name in zip(unique_squad_ids, unique_squad_names):\n",
    "    for season in seasons:\n",
    "        url = f\"https://fbref.com/en/squads/{squad_id}/{season}/matchlogs/all_comps/shooting/{squad_name.replace(' ', '-')}-Scores-and-Fixtures-All-Competitions\"\n",
    "        squad_urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_squad_data = list(zip(squad_urls, match_logs['squad_id'], match_logs['squad']))\n",
    "\n",
    "squad_dfs = []\n",
    "with tqdm(total=len(url_squad_data), desc=\"Processing URLs\") as pbar:\n",
    "    for url, squad_id, squad_name in url_squad_data:\n",
    "        try:\n",
    "            with requests.Session() as session:\n",
    "                data = session.get(url, headers=headers)\n",
    "                soup = BeautifulSoup(data.text, \"html.parser\")\n",
    "\n",
    "                table = soup.find(\"table\", {\"id\": \"matchlogs_for\"})\n",
    "\n",
    "                df = pd.read_html(StringIO(str(table)))[0]\n",
    "                df.columns = [\n",
    "                    f\"{i} {j}\" if \"Unnamed\" not in i else j for i, j in df.columns\n",
    "                ]\n",
    "                \n",
    "                df['squad_id'] = squad_id\n",
    "                df['squad_name'] = squad_name\n",
    "                \n",
    "                squad_dfs.append(df)\n",
    "                \n",
    "                time.sleep(6)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for URL: {url}: {e}\")\n",
    "\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_logs_squads = pd.concat(squad_dfs)\n",
    "match_logs_squads = match_logs_squads.rename ({\n",
    "    \"Expected xG\": \"xG\", \"Expected npxG\": \"npxG\", \"Expected npxG/Sh\": \"npxG/Sh\",\n",
    "    }, axis=1)\n",
    "match_logs_squads.dropna(inplace=True)\n",
    "match_logs_squads.columns = match_logs_squads.columns.str.lower()\n",
    "#match_logs_squads = match_logs_squads[['date', 'squad_id', 'squad', 'comp', 'round', 'venue', 'result', 'gf', 'ga', 'opponent', 'xg', 'npxg', 'npxg/sh']]\n",
    "match_logs_squads['squad_name'] = match_logs_squads['squad_name'].str.replace(r'\\b[a-z]+\\b', '', regex=True).str.strip()\n",
    "#match_logs_squads['opponent'] = match_logs_squads['opponent'].str.replace(r'\\b[a-z]+\\b', '', regex=True).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_logs_squads.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
