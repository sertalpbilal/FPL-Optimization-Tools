{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total season rows found for https://fbref.com/en/comps/9/history/Premier-League-Seasons: 127\n",
      "Match found for season: /2023-2024\n",
      "Final URL: https://fbref.com/en/comps/9/2023-2024/stats/teams/2023-2024-Premier-League-Stats\n",
      "Match found for season: 2022-2023\n",
      "Final URL: https://fbref.com/en/comps/9/2022-2023/stats/teams/2022-2023-Premier-League-Stats\n",
      "Match found for season: 2021-2022/\n",
      "Final URL: https://fbref.com/en/comps/9/2021-2022/stats/teams/2021-2022-Premier-League-Stats\n",
      "Total season rows found for https://fbref.com/en/comps/10/history/Championship-Seasons: 25\n",
      "Match found for season: /2023-2024\n",
      "Final URL: https://fbref.com/en/comps/10/2023-2024/stats/teams/2023-2024-Championship-Stats\n",
      "Match found for season: 2022-2023\n",
      "Final URL: https://fbref.com/en/comps/10/2022-2023/stats/teams/2022-2023-Championship-Stats\n",
      "Match found for season: 2021-2022/\n",
      "Final URL: https://fbref.com/en/comps/10/2021-2022/stats/teams/2021-2022-Championship-Stats\n",
      "Total season stats URLs: 6\n",
      "All season stats URLs:\n",
      "['https://fbref.com/en/comps/9/2023-2024/stats/teams/2023-2024-Premier-League-Stats', 'https://fbref.com/en/comps/9/2022-2023/stats/teams/2022-2023-Premier-League-Stats', 'https://fbref.com/en/comps/9/2021-2022/stats/teams/2021-2022-Premier-League-Stats', 'https://fbref.com/en/comps/10/2023-2024/stats/teams/2023-2024-Championship-Stats', 'https://fbref.com/en/comps/10/2022-2023/stats/teams/2022-2023-Championship-Stats', 'https://fbref.com/en/comps/10/2021-2022/stats/teams/2021-2022-Championship-Stats']\n"
     ]
    }
   ],
   "source": [
    "desired_seasons = [\"2023-2024\", \"2022-2023\", \"2021-2022\"]\n",
    "\n",
    "base_urls = [\n",
    "    \"https://fbref.com/en/comps/9/history/Premier-League-Seasons\",  # Premier League\n",
    "    \"https://fbref.com/en/comps/10/history/Championship-Seasons\",  # Championship\n",
    "]\n",
    "\n",
    "season_stats_urls = []\n",
    "seasons_pattern = \"|\".join(desired_seasons)\n",
    "\n",
    "with requests.Session() as session:\n",
    "    for base_url in base_urls:\n",
    "        response = session.get(base_url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        table = soup.find(\"table\", {\"id\": \"seasons\"})\n",
    "        table_rows = table.find_all(\"tr\")\n",
    "\n",
    "        print(f\"Total season rows found for {base_url}: {len(table_rows)}\")\n",
    "\n",
    "        for row in table_rows:\n",
    "            a_tag = row.find(\"a\", href=True)\n",
    "            if a_tag:\n",
    "                row_href = a_tag[\"href\"]\n",
    "                season = re.search(rf\"/{seasons_pattern}/\", row_href)\n",
    "                if season:\n",
    "                    print(f\"Match found for season: {season.group(0)}\")\n",
    "\n",
    "                    modified_href = re.sub(r\"(/[^/]+)$\", r\"/stats/teams\\1\", row_href)\n",
    "                    full_url = f\"https://fbref.com{modified_href}\"\n",
    "                    season_stats_urls.append(full_url)\n",
    "\n",
    "                    print(f\"Final URL: {full_url}\")\n",
    "\n",
    "        time.sleep(3)  # Dynamic adjustment could be added here\n",
    "\n",
    "print(f\"Total season stats URLs: {len(season_stats_urls)}\")\n",
    "print(f\"All season stats URLs:\\n{season_stats_urls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_url(url):\n",
    "    try:\n",
    "        # Fetch and parse the page content\n",
    "        data = requests.get(url).text.replace(\"<!--\", \"\").replace(\"-->\", \"\")\n",
    "        soup = BeautifulSoup(data, \"html.parser\")\n",
    "\n",
    "        # Extract season and competition information\n",
    "        season = re.search(r\"/(\\d{4}-\\d{4})/\", url).group(1)\n",
    "        h2_element = soup.find(\"h2\")\n",
    "        competition = (\n",
    "            \" \".join(h2_element.find(\"span\").get_text().split()[1:])\n",
    "            if h2_element and h2_element.find(\"span\")\n",
    "            else pd.NA\n",
    "        )\n",
    "\n",
    "        # Initialize empty DataFrames\n",
    "        df_for = pd.DataFrame()\n",
    "        df_against = pd.DataFrame()\n",
    "\n",
    "        # Extract the 'for' data table\n",
    "        table_for = soup.find(\"table\", {\"id\": \"stats_squads_standard_for\"})\n",
    "        if table_for is not None:\n",
    "            df_for = pd.read_html(StringIO(str(table_for)))[0]\n",
    "            df_for.columns = [\n",
    "                f\"{i} {j}\" if \"Unnamed\" not in i else j for i, j in df_for.columns\n",
    "            ]\n",
    "            df_for[\"Season\"] = season\n",
    "            df_for[\"Competition\"] = competition\n",
    "\n",
    "        # Extract the 'against' data table\n",
    "        table_against = soup.find(\"table\", {\"id\": \"stats_squads_standard_against\"})\n",
    "        if table_against is not None:\n",
    "            df_against = pd.read_html(StringIO(str(table_against)))[0]\n",
    "            df_against.columns = [\n",
    "                f\"{i} {j}\" if \"Unnamed\" not in i else j for i, j in df_against.columns\n",
    "            ]\n",
    "            df_against[\"Season\"] = season\n",
    "            df_against[\"Competition\"] = competition\n",
    "\n",
    "        # Rename relevant columns\n",
    "        rename_for = {\n",
    "            \"Playing Time 90s\": \"90s\",\n",
    "            \"Per 90 Minutes npxG\": \"npxG\",\n",
    "        }\n",
    "        df_for = df_for.rename(rename_for, axis=1)\n",
    "\n",
    "        rename_against = {\n",
    "            \"Playing Time 90s\": \"90s\",\n",
    "            \"Per 90 Minutes npxG\": \"npxGC\",\n",
    "        }\n",
    "        df_against = df_against.rename(rename_against, axis=1)\n",
    "\n",
    "        # Keep only Squad, Season, Competition, and renamed columns\n",
    "        selected_columns_for = [\"Squad\", \"Season\", \"Competition\"] + list(rename_for.values())\n",
    "        selected_columns_against = [\"Squad\", \"Season\", \"Competition\"] + list(rename_against.values())\n",
    "\n",
    "        if \"Squad\" in df_for.columns:\n",
    "            df_for = df_for[selected_columns_for]\n",
    "        if \"Squad\" in df_against.columns:\n",
    "            df_against = df_against[selected_columns_against]\n",
    "            \n",
    "        df_against['Squad'] = df_against['Squad'].str.replace('vs ', '', regex=False)\n",
    "\n",
    "        return df_for, df_against\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for URL: {url} - {e}\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL: https://fbref.com/en/comps/9/2023-2024/stats/teams/2023-2024-Premier-League-Stats\n",
      "Processing URL: https://fbref.com/en/comps/9/2022-2023/stats/teams/2022-2023-Premier-League-Stats\n",
      "Processing URL: https://fbref.com/en/comps/9/2021-2022/stats/teams/2021-2022-Premier-League-Stats\n",
      "Processing URL: https://fbref.com/en/comps/10/2023-2024/stats/teams/2023-2024-Championship-Stats\n",
      "Processing URL: https://fbref.com/en/comps/10/2022-2023/stats/teams/2022-2023-Championship-Stats\n",
      "Processing URL: https://fbref.com/en/comps/10/2021-2022/stats/teams/2021-2022-Championship-Stats\n",
      "Combined DataFrame 'For':\n",
      "         Squad     Season     Competition   90s  npxG\n",
      "0      Arsenal  2023-2024  Premier League  38.0  1.80\n",
      "1  Aston Villa  2023-2024  Premier League  38.0  1.59\n",
      "2  Bournemouth  2023-2024  Premier League  38.0  1.41\n",
      "3    Brentford  2023-2024  Premier League  38.0  1.47\n",
      "4     Brighton  2023-2024  Premier League  38.0  1.37\n",
      "Combined DataFrame 'Against':\n",
      "         Squad     Season     Competition   90s  npxGC\n",
      "0      Arsenal  2023-2024  Premier League  38.0   0.68\n",
      "1  Aston Villa  2023-2024  Premier League  38.0   1.53\n",
      "2  Bournemouth  2023-2024  Premier League  38.0   1.38\n",
      "3    Brentford  2023-2024  Premier League  38.0   1.43\n",
      "4     Brighton  2023-2024  Premier League  38.0   1.33\n"
     ]
    }
   ],
   "source": [
    "combined_df_for = pd.DataFrame()\n",
    "combined_df_against = pd.DataFrame()\n",
    "\n",
    "for url in season_stats_urls:\n",
    "    print(f\"Processing URL: {url}\")\n",
    "    df_for, df_against = extract_data_from_url(url)\n",
    "    \n",
    "    if not df_for.empty:\n",
    "        combined_df_for = pd.concat([combined_df_for, df_for], ignore_index=True)\n",
    "    if not df_against.empty:\n",
    "        combined_df_against = pd.concat([combined_df_against, df_against], ignore_index=True)\n",
    "\n",
    "print(\"Combined DataFrame 'For':\")\n",
    "print(combined_df_for.head())\n",
    "\n",
    "print(\"Combined DataFrame 'Against':\")\n",
    "print(combined_df_against.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Combined DataFrame 'Against':\n",
      "         Squad     Season     Competition   90s  npxGC\n",
      "0      Arsenal  2023-2024  Premier League  38.0   0.68\n",
      "1  Aston Villa  2023-2024  Premier League  38.0   1.53\n",
      "2  Bournemouth  2023-2024  Premier League  38.0   1.38\n",
      "3    Brentford  2023-2024  Premier League  38.0   1.43\n",
      "4     Brighton  2023-2024  Premier League  38.0   1.33\n"
     ]
    }
   ],
   "source": [
    "# Remove the 'vs ' prefix from the 'Squad' column in combined_df_against\n",
    "combined_df_against['Squad'] = combined_df_against['Squad'].str.replace('vs ', '', regex=False)\n",
    "\n",
    "# Display the updated 'combined_df_against' DataFrame to verify the changes\n",
    "print(\"Updated Combined DataFrame 'Against':\")\n",
    "print(combined_df_against.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted DataFrame 'For':\n",
      "              Squad    90s    npxG\n",
      "23        Liverpool  114.0  2.0620\n",
      "25  Manchester City  114.0  1.9320\n",
      "0           Arsenal  114.0  1.7670\n",
      "29    Newcastle Utd  114.0  1.7220\n",
      "44        Tottenham  114.0  1.6520\n",
      "12          Chelsea  114.0  1.5940\n",
      "1       Aston Villa  114.0  1.4710\n",
      "8          Brighton  114.0  1.4280\n",
      "26   Manchester Utd  114.0  1.4180\n",
      "7         Brentford  114.0  1.4010\n",
      "16          Everton  114.0  1.2720\n",
      "6       Bournemouth  122.0  1.2660\n",
      "47         West Ham  114.0  1.2420\n",
      "17           Fulham  122.0  1.2135\n",
      "31  Nott'ham Forest  122.0  1.1540\n",
      "14   Crystal Palace  114.0  1.1400\n",
      "49           Wolves  114.0  1.0840\n",
      "10          Burnley  122.0  0.9460\n",
      "22   Leicester City  122.0  0.9290\n",
      "24       Luton Town  130.0  0.8985\n",
      "21     Leeds United  122.0  0.8950\n",
      "40      Southampton  122.0  0.8695\n",
      "38    Sheffield Utd  130.0  0.8640\n",
      "20     Ipswich Town   46.0  0.7800\n",
      "27    Middlesbrough  138.0  0.7005\n",
      "30     Norwich City  130.0  0.6660\n",
      "13    Coventry City  138.0  0.6505\n",
      "46        West Brom  138.0  0.6335\n",
      "4         Blackburn  138.0  0.6175\n",
      "45          Watford  130.0  0.6160\n",
      "42       Sunderland   92.0  0.6080\n",
      "43     Swansea City  138.0  0.5900\n",
      "41       Stoke City  138.0  0.5635\n",
      "33  Plymouth Argyle   46.0  0.5600\n",
      "39   Sheffield Weds   46.0  0.5450\n",
      "19        Hull City  138.0  0.5400\n",
      "9      Bristol City  138.0  0.5380\n",
      "3   Birmingham City  138.0  0.5165\n",
      "18     Huddersfield  138.0  0.5155\n",
      "5         Blackpool   92.0  0.5140\n",
      "28         Millwall  138.0  0.4990\n",
      "35              QPR  138.0  0.4835\n",
      "11     Cardiff City  138.0  0.4735\n",
      "15     Derby County   46.0  0.4700\n",
      "32    P'borough Utd   46.0  0.4650\n",
      "48   Wigan Athletic   46.0  0.4650\n",
      "2          Barnsley   46.0  0.4550\n",
      "34          Preston  138.0  0.4480\n",
      "36          Reading   92.0  0.4240\n",
      "37    Rotherham Utd   92.0  0.3550\n",
      "Weighted DataFrame 'Against':\n",
      "              Squad    90s  npxGC\n",
      "0           Arsenal  114.0  0.784\n",
      "25  Manchester City  114.0  0.828\n",
      "23        Liverpool  114.0  1.167\n",
      "14   Crystal Palace  114.0  1.252\n",
      "8          Brighton  114.0  1.266\n",
      "12          Chelsea  114.0  1.342\n",
      "16          Everton  114.0  1.365\n",
      "7         Brentford  114.0  1.368\n",
      "29    Newcastle Utd  114.0  1.384\n",
      "44        Tottenham  114.0  1.421\n",
      "1       Aston Villa  114.0  1.439\n",
      "31  Nott'ham Forest  122.0  1.444\n",
      "6       Bournemouth  122.0  1.466\n",
      "17           Fulham  122.0  1.526\n",
      "47         West Ham  114.0  1.544\n",
      "26   Manchester Utd  114.0  1.551\n",
      "49           Wolves  114.0  1.562\n",
      "21     Leeds United  122.0  1.630\n",
      "10          Burnley  122.0  1.649\n",
      "22   Leicester City  122.0  1.726\n",
      "38    Sheffield Utd  130.0  1.883\n",
      "40      Southampton  122.0  1.890\n",
      "20     Ipswich Town   46.0  1.920\n",
      "46        West Brom  138.0  1.938\n",
      "24       Luton Town  130.0  1.947\n",
      "42       Sunderland   92.0  2.088\n",
      "45          Watford  130.0  2.151\n",
      "27    Middlesbrough  138.0  2.178\n",
      "28         Millwall  138.0  2.178\n",
      "41       Stoke City  138.0  2.268\n",
      "19        Hull City  138.0  2.270\n",
      "35              QPR  138.0  2.284\n",
      "39   Sheffield Weds   46.0  2.300\n",
      "9      Bristol City  138.0  2.306\n",
      "13    Coventry City  138.0  2.308\n",
      "48   Wigan Athletic   46.0  2.320\n",
      "30     Norwich City  130.0  2.433\n",
      "34          Preston  138.0  2.460\n",
      "4         Blackburn  138.0  2.536\n",
      "18     Huddersfield  138.0  2.554\n",
      "3   Birmingham City  138.0  2.580\n",
      "36          Reading   92.0  2.628\n",
      "43     Swansea City  138.0  2.634\n",
      "15     Derby County   46.0  2.700\n",
      "11     Cardiff City  138.0  2.760\n",
      "5         Blackpool   92.0  2.890\n",
      "33  Plymouth Argyle   46.0  3.060\n",
      "37    Rotherham Utd   92.0  3.114\n",
      "2          Barnsley   46.0  3.300\n",
      "32    P'borough Utd   46.0  3.540\n",
      "'For' data successfully saved to team_stats_for.csv\n",
      "'Against' data successfully saved to team_stats_against.csv\n"
     ]
    }
   ],
   "source": [
    "def calculate_weighted_npx(df, is_for=True):\n",
    "    def apply_league_multiplier(row):\n",
    "        if row['Competition'] == 'Premier League':\n",
    "            return 1  # No change for Premier League\n",
    "        elif row['Competition'] == 'Championship':\n",
    "            return 0.5 if is_for else 2  # Different multipliers for npxG and npxGC\n",
    "        return 1  # Default multiplier if league is neither\n",
    "\n",
    "    def weighted_avg(series, weights):\n",
    "        return (series * weights).sum() / weights.sum()\n",
    "\n",
    "    def process_team(group):\n",
    "        num_seasons = len(group)\n",
    "        group = group.sort_values(by='Season', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        # Define weights based on number of seasons\n",
    "        if num_seasons == 1:\n",
    "            recency_weights = pd.Series([1], index=group.index)  # Single season gets weight of 1\n",
    "        elif num_seasons == 2:\n",
    "            recency_weights = pd.Series([0.7, 0.3], index=group.index)  # Two seasons with weights 0.7 and 0.3\n",
    "        else:\n",
    "            recency_weights = pd.Series([0.7, 0.2, 0.1], index=group.index)  # Three seasons with weights 0.7, 0.2, and 0.1\n",
    "        \n",
    "        # Ensure weights match the length of the group\n",
    "        recency_weights = recency_weights.head(num_seasons)\n",
    "\n",
    "        # Apply league multipliers\n",
    "        if is_for:\n",
    "            group['npxG'] *= group.apply(apply_league_multiplier, axis=1)\n",
    "            series_to_weight = group['npxG']\n",
    "        else:\n",
    "            group['npxGC'] *= group.apply(apply_league_multiplier, axis=1)\n",
    "            series_to_weight = group['npxGC']\n",
    "\n",
    "        # Calculate weighted averages\n",
    "        weighted_value = weighted_avg(series_to_weight, recency_weights)\n",
    "        \n",
    "        # Calculate the sum of the '90s' column\n",
    "        total_90s = group['90s'].sum()\n",
    "\n",
    "        return pd.Series({\n",
    "            'Squad': group['Squad'].iloc[0],\n",
    "            '90s': total_90s,\n",
    "            'npxG' if is_for else 'npxGC': weighted_value\n",
    "        })\n",
    "\n",
    "    df_grouped = df.groupby('Squad')\n",
    "    \n",
    "    df_grouped = df_grouped[['Squad', 'Season', 'Competition', '90s', 'npxG'] if is_for else ['Squad', 'Season', 'Competition','90s', 'npxGC']]\n",
    "\n",
    "    # Process each squad while excluding the grouping columns\n",
    "    weighted_df = df_grouped.apply(process_team).reset_index(drop=True)\n",
    "\n",
    "    return weighted_df\n",
    "\n",
    "# Calculate weighted npxG for df_for\n",
    "weighted_df_for = calculate_weighted_npx(combined_df_for, is_for=True)\n",
    "print(\"Weighted DataFrame 'For':\")\n",
    "print(weighted_df_for.sort_values(by=\"npxG\", ascending=False))\n",
    "\n",
    "# Calculate weighted npxGC for df_against\n",
    "weighted_df_against = calculate_weighted_npx(combined_df_against, is_for=False)\n",
    "print(\"Weighted DataFrame 'Against':\")\n",
    "print(weighted_df_against.sort_values(by=\"npxGC\", ascending=True))\n",
    "\n",
    "csv_file_path = \"C:/Users/erknud3/fpl-optimization/model/data\"\n",
    "\n",
    "if not weighted_df_for.empty:\n",
    "    weighted_df_for.to_csv(f\"{csv_file_path}/team_stats_for.csv\", index=False)\n",
    "    print(f\"'For' data successfully saved to team_stats_for.csv\")\n",
    "else:\n",
    "    print(\"No 'for' data to save.\")\n",
    "\n",
    "if not weighted_df_against.empty:\n",
    "    weighted_df_against.to_csv(\n",
    "        f\"{csv_file_path}/team_stats_against.csv\", index=False\n",
    "    )\n",
    "    print(f\"'Against' data successfully saved to team_stats_against.csv\")\n",
    "else:\n",
    "    print(\"No 'against' data to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_stats_new_season(url):\n",
    "    try:\n",
    "        # Fetch and parse the page content\n",
    "        data = requests.get(url).text.replace(\"<!--\", \"\").replace(\"-->\", \"\")\n",
    "        soup = BeautifulSoup(data, \"html.parser\")\n",
    "\n",
    "        # Initialize empty DataFrames\n",
    "        df_for = pd.DataFrame()\n",
    "        df_against = pd.DataFrame()\n",
    "\n",
    "        # Extract the 'for' data table\n",
    "        table_for = soup.find(\"table\", {\"id\": \"stats_squads_standard_for\"})\n",
    "        if table_for is not None:\n",
    "            df_for = pd.read_html(StringIO(str(table_for)))[0]\n",
    "            df_for.columns = [\n",
    "                f\"{i} {j}\" if \"Unnamed\" not in i else j for i, j in df_for.columns\n",
    "            ]\n",
    "\n",
    "        # Extract the 'against' data table\n",
    "        table_against = soup.find(\"table\", {\"id\": \"stats_squads_standard_against\"})\n",
    "        if table_against is not None:\n",
    "            df_against = pd.read_html(StringIO(str(table_against)))[0]\n",
    "            df_against.columns = [\n",
    "                f\"{i} {j}\" if \"Unnamed\" not in i else j for i, j in df_against.columns\n",
    "            ]\n",
    "\n",
    "        # Rename relevant columns\n",
    "        rename_for = {\n",
    "            \"Playing Time 90s\": \"90s\",\n",
    "            \"Per 90 Minutes npxG\": \"npxG\",\n",
    "        }\n",
    "        df_for = df_for.rename(rename_for, axis=1)\n",
    "\n",
    "        rename_against = {\n",
    "            \"Playing Time 90s\": \"90s\",\n",
    "            \"Per 90 Minutes npxG\": \"npxGC\",\n",
    "        }\n",
    "        df_against = df_against.rename(rename_against, axis=1)\n",
    "\n",
    "        # Keep only Squad, Season, Competition, and renamed columns\n",
    "        selected_columns_for = [\"Squad\"] + list(\n",
    "            rename_for.values()\n",
    "        )\n",
    "        selected_columns_against = [\"Squad\"] + list(\n",
    "            rename_against.values()\n",
    "        )\n",
    "\n",
    "        if \"Squad\" in df_for.columns:\n",
    "            df_for = df_for[selected_columns_for]\n",
    "        if \"Squad\" in df_against.columns:\n",
    "            df_against = df_against[selected_columns_against]\n",
    "\n",
    "        # Remove the 'vs ' prefix from the 'Squad' column in combined_df_against\n",
    "        df_against[\"Squad\"] = df_against[\"Squad\"].str.replace(\"vs \", \"\", regex=False)\n",
    "\n",
    "        return df_for, df_against\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for URL: {url} - {e}\")\n",
    "        return pd.DataFrame(), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new season stats\n",
    "new_season = get_team_stats_new_season(\n",
    "    \"https://fbref.com/en/comps/9/stats/Premier-League-Stats\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_for = pd.DataFrame()\n",
    "new_df_against = pd.DataFrame()\n",
    "\n",
    "df_for, df_against = get_team_stats_new_season(\"https://fbref.com/en/comps/9/stats/Premier-League-Stats\")\n",
    "\n",
    "if not df_for.empty and not df_against.empty:\n",
    "    new_df_for = pd.concat([new_df_for, df_for], ignore_index=True)\n",
    "    new_df_against = pd.concat(\n",
    "        [new_df_against, df_against], ignore_index=True\n",
    "    )\n",
    "else:\n",
    "    print(f\"No data extracted for URL: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_previous_seasons_for = pd.read_csv(\"C:/Users/erknud3/fpl-optimization/model/data/team_stats_for.csv\")\n",
    "teams_previous_seasons_against = pd.read_csv(\"C:/Users/erknud3/fpl-optimization/model/data/team_stats_against.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_season_for = pd.merge(teams_previous_seasons_for, new_df_for, on=\"Squad\", how=\"inner\", suffixes=(\"\", \"_new\"))\n",
    "new_season_against = pd.merge(teams_previous_seasons_against, new_df_against, on=\"Squad\", how=\"inner\", suffixes=(\"\", \"_new\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_season_for.insert(0, 'team_id', range(1,21))\n",
    "new_season_against.insert(0, 'team_id', range(1,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_stats(df, is_for=True, weight_new_data=1.0):\n",
    "    \"\"\"Calculate weighted stats with additional weight for new data.\"\"\"\n",
    "    # Calculate total 90s for normalization\n",
    "    total_90s = df[\"90s\"] + df[\"90s_new\"]\n",
    "\n",
    "    # Apply additional weight to new data\n",
    "    weight_old_data = 1.0\n",
    "    weight_new_data = float(weight_new_data)\n",
    "    \n",
    "    if is_for:\n",
    "        df[\"weighted_npxG\"] = (\n",
    "            (df[\"npxG\"] * df[\"90s\"] / total_90s * weight_old_data)\n",
    "            + (\n",
    "                df[\"npxG_new\"]\n",
    "                * df[\"90s_new\"]\n",
    "                / total_90s\n",
    "                * weight_new_data\n",
    "            )\n",
    "        ).round(2)\n",
    "    else:\n",
    "        df[\"weighted_npxGC\"] = (\n",
    "            (df[\"npxGC\"] * df[\"90s\"] / total_90s * weight_old_data)\n",
    "            + (\n",
    "                df[\"npxGC_new\"]\n",
    "                * df[\"90s_new\"]\n",
    "                / total_90s\n",
    "                * weight_new_data\n",
    "            )\n",
    "        ).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'For' data successfully saved to teams_new_season_for_gw.csv\n",
      "'For' data successfully saved to teams_new_season_against_gw.csv\n"
     ]
    }
   ],
   "source": [
    "# Calculate weighted stats\n",
    "teams_new_season_for = calculate_weighted_stats(new_season_for, is_for=True, weight_new_data=1.5)\n",
    "teams_new_season_against = calculate_weighted_stats(new_season_against, is_for=False, weight_new_data=1.5)\n",
    "\n",
    "max_mp = new_season_for[\"90s_new\"].max().astype(int)\n",
    "\n",
    "csv_file_path = \"C:/Users/erknud3/fpl-optimization/model/data\"\n",
    "\n",
    "if not new_season_for.empty:\n",
    "    new_season_for.to_csv(f\"{csv_file_path}/teams_new_season_for_gw{max_mp}.csv\", index=False)\n",
    "    print(f\"'For' data successfully saved to teams_new_season_for_gw.csv\")\n",
    "else:\n",
    "    print(\"No 'for' data to save.\")\n",
    "\n",
    "if not new_season_against.empty:\n",
    "    new_season_against.to_csv(f\"{csv_file_path}/teams_new_season_against_gw{max_mp}.csv\", index=False)\n",
    "    print(f\"'Against' data successfully saved to teams_new_season_against_gw.csv\")\n",
    "else:\n",
    "    print(\"No 'against' data to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in fpl_players_new_season after loading: Index(['fbref', 'fpl_id', 'first_name', 'second_name', 'Player', 'web_name',\n",
      "       'Age', 'team_id', 'team_name', 'short_name', 'element_type', 'position',\n",
      "       'Seasons_count', 'now_cost', 'tsb', 'MP', 'Starts', 'Min', '90s',\n",
      "       'npxG', 'xAG', 'finishing', 'MP_new', '90s_new', 'npxG_new', 'xAG_new',\n",
      "       'weighted_npxG', 'weighted_xAG'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "newest_gw = 3\n",
    "\n",
    "# Load the necessary CSV files\n",
    "fpl_players_path = f\"C:/Users/erknud3/fpl-optimization/model/data/New_Season_Data/fpl_players_new_season_gw{newest_gw}.csv\"\n",
    "teams_pred_npxG_path = f\"C:/Users/erknud3/fpl-optimization/model/data/Prediction_Data/teams_pred_npxG_gw{newest_gw}.csv\"\n",
    "gc_probs_path = f\"C:/Users/erknud3/fpl-optimization/model/data/Prediction_Data/GC_probabilities.csv\"\n",
    "pen_share_path = f\"C:/Users/erknud3/fpl-optimization/model/data/Prediction_Data/pen_share.csv\"\n",
    "\n",
    "# Check if files exist\n",
    "if not (\n",
    "    os.path.exists(fpl_players_path)\n",
    "    and os.path.exists(teams_pred_npxG_path)\n",
    "    and os.path.exists(gc_probs_path)\n",
    "):\n",
    "    raise FileNotFoundError(\n",
    "        f\"One or more necessary files do not exist for gameweek {newest_gw}.\"\n",
    "    )\n",
    "\n",
    "fpl_players_new_season = pd.read_csv(fpl_players_path)\n",
    "teams_pred_npxG = pd.read_csv(teams_pred_npxG_path)\n",
    "gc_probs = pd.read_csv(gc_probs_path)\n",
    "pen_share = pd.read_csv(pen_share_path)\n",
    "\n",
    "# Check if 'weighted_xAG' exists immediately after loading the DataFrame\n",
    "print(\n",
    "    \"Columns in fpl_players_new_season after loading:\",\n",
    "    fpl_players_new_season.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define position multipliers\n",
    "position_multipliers = {\n",
    "1: 10,\n",
    "2: 6,\n",
    "3: 5,\n",
    "4: 4,\n",
    "}  # GKP, DEF, MID, FWD multipliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Player     1\n",
      "202          Diogo Jota  3.39\n",
      "107       Mohamed Salah  3.22\n",
      "279      Alexander Isak  2.94\n",
      "423        Darwin Núñez  2.93\n",
      "301      Erling Haaland  2.68\n",
      "225       Harvey Barnes  2.51\n",
      "357           Luis Díaz  2.37\n",
      "453       Ali Al Hamadi  2.19\n",
      "50        Son Heung-min  2.12\n",
      "523  Alejandro Garnacho  2.12\n"
     ]
    }
   ],
   "source": [
    "# Generate player_xp_goals\n",
    "columns_to_keep = [\n",
    "    \"fpl_id\",\n",
    "    \"Player\",\n",
    "    \"web_name\",\n",
    "    \"Age\",\n",
    "    \"team_name\",\n",
    "    \"team_id\",\n",
    "    \"element_type\",\n",
    "    \"now_cost\",\n",
    "    \"tsb\",\n",
    "    \"Min\",\n",
    "    \"90s\",\n",
    "    \"finishing\",\n",
    "    \"MP_new\",\n",
    "    \"90s_new\",\n",
    "    \"weighted_npxG\",\n",
    "]\n",
    "player_xp_goals = fpl_players_new_season[columns_to_keep].copy()\n",
    "\n",
    "for gw in range(1, 39):\n",
    "    gw_column = str(gw)\n",
    "    player_xp_goals[gw_column] = player_xp_goals.apply(\n",
    "        lambda row: row[\"weighted_npxG\"]\n",
    "        * teams_pred_npxG.loc[\n",
    "            teams_pred_npxG[\"team_id\"] == row[\"team_id\"], gw_column\n",
    "        ].values[0]\n",
    "        * row[\"finishing\"]\n",
    "        * position_multipliers[row[\"element_type\"]],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "player_xp_goals = player_xp_goals.round(2)\n",
    "\n",
    "xp_goals_1 = player_xp_goals[[\"Player\", \"1\"]]\n",
    "\n",
    "print(xp_goals_1.sort_values(by=\"1\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Player     1\n",
      "109          Mohamed Salah  0.47\n",
      "281         Alexander Isak  0.44\n",
      "304            Bukayo Saka  0.43\n",
      "33           Callum Wilson  0.42\n",
      "424           Bryan Mbeumo  0.39\n",
      "52           Son Heung-min  0.37\n",
      "124        Bruno Fernandes  0.37\n",
      "298     Morgan Gibbs-White  0.36\n",
      "76             Jamie Vardy  0.34\n",
      "180  Dominic Calvert-Lewin  0.31\n"
     ]
    }
   ],
   "source": [
    "# Generate player_xp_pens\n",
    "player_xp_pens = fpl_players_new_season[columns_to_keep].copy()\n",
    "\n",
    "# Merge player_xp_pens with pen_share to get the penalty share for each player\n",
    "player_xp_pens = player_xp_pens.merge(\n",
    "    pen_share[[\"fpl_id\", \"pen_share\"]], on=\"fpl_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Fill missing pen_share values with 0 (players who don't take penalties)\n",
    "player_xp_pens[\"pen_share\"] = player_xp_pens[\"pen_share\"].fillna(0)\n",
    "\n",
    "for gw in range(1, 39):\n",
    "    gw_column = str(gw)\n",
    "    player_xp_pens[gw_column] = player_xp_pens.apply(\n",
    "        lambda row: (\n",
    "            (\n",
    "                0.1\n",
    "                * teams_pred_npxG.loc[\n",
    "                    teams_pred_npxG[\"team_id\"] == row[\"team_id\"], gw_column\n",
    "                ].values[0]\n",
    "                * 0.77\n",
    "                * position_multipliers[row[\"element_type\"]]\n",
    "                * row[\"pen_share\"]\n",
    "            )\n",
    "            if row[\"pen_share\"] > 0\n",
    "            else 0\n",
    "        ),  # Ensure EV is 0 if pen_share is 0\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "player_xp_pens = player_xp_pens.round(2)\n",
    "\n",
    "xp_pens_1 = player_xp_pens[[\"Player\", \"1\"]]\n",
    "\n",
    "print(xp_pens_1.sort_values(by=\"1\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Player     1\n",
      "28          Kevin De Bruyne  1.52\n",
      "122         Bruno Fernandes  1.33\n",
      "100            Jacob Murphy  1.30\n",
      "35          Kieran Trippier  1.30\n",
      "163  Trent Alexander-Arnold  1.24\n",
      "107           Mohamed Salah  1.21\n",
      "302             Bukayo Saka  1.07\n",
      "413      Gabriel Martinelli  1.03\n",
      "423            Darwin Núñez  0.99\n",
      "334          Anthony Gordon  0.94\n"
     ]
    }
   ],
   "source": [
    "# Generate player_xp_assists\n",
    "columns_to_keep_assists = [\n",
    "    \"fpl_id\",\n",
    "    \"Player\",\n",
    "    \"web_name\",\n",
    "    \"Age\",\n",
    "    \"team_name\",\n",
    "    \"team_id\",\n",
    "    \"element_type\",\n",
    "    \"now_cost\",\n",
    "    \"tsb\",\n",
    "    \"Min\",\n",
    "    \"90s\",\n",
    "    \"MP_new\",\n",
    "    \"90s_new\",\n",
    "    \"weighted_xAG\",\n",
    "]\n",
    "player_xp_assists = fpl_players_new_season[columns_to_keep_assists].copy()\n",
    "\n",
    "if \"weighted_xAG\" not in fpl_players_new_season.columns:\n",
    "    raise KeyError(\n",
    "        f\"'weighted_xAG' not found in fpl_players_new_season DataFrame columns: {fpl_players_new_season.columns}\"\n",
    "    )\n",
    "\n",
    "for gw in range(1, 39):\n",
    "    gw_column = str(gw)\n",
    "    player_xp_assists[gw_column] = player_xp_assists.apply(\n",
    "        lambda row: row[\"weighted_xAG\"]\n",
    "        * teams_pred_npxG.loc[\n",
    "            teams_pred_npxG[\"team_id\"] == row[\"team_id\"], gw_column\n",
    "        ].values[0]\n",
    "        * 3,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "player_xp_assists = player_xp_assists.round(2)\n",
    "\n",
    "xp_assits_1 = player_xp_assists[[\"Player\", \"1\"]]\n",
    "\n",
    "print(xp_assits_1.sort_values(by=\"1\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Player     1\n",
      "240  Oleksandr Zinchenko  2.19\n",
      "459      Karl Jakob Hein  2.19\n",
      "402         Jakub Kiwior  2.19\n",
      "210            Ben White  2.19\n",
      "313    Gabriel Magalhães  2.19\n",
      "137           David Raya  2.19\n",
      "197       Kieran Tierney  2.19\n",
      "31                  Neto  2.19\n",
      "304    Takehiro Tomiyasu  2.19\n",
      "466                  NaN  2.19\n"
     ]
    }
   ],
   "source": [
    "# Generate player_xp_cs\n",
    "columns_to_keep_cs = [\n",
    "    \"fpl_id\",\n",
    "    \"Player\",\n",
    "    \"web_name\",\n",
    "    \"Age\",\n",
    "    \"team_name\",\n",
    "    \"team_id\",\n",
    "    \"element_type\",\n",
    "    \"now_cost\",\n",
    "    \"tsb\",\n",
    "    \"Min\",\n",
    "    \"90s\",\n",
    "    \"MP_new\",\n",
    "    \"90s_new\",\n",
    "]\n",
    "player_xp_cs = fpl_players_new_season[columns_to_keep_cs].copy()\n",
    "\n",
    "points_per_goal_scenario = {\n",
    "    0: {1: 4, 2: 4, 3: 1, 4: 0},\n",
    "    1: 0,\n",
    "    2: {1: -1, 2: -1, 3: 0, 4: 0},\n",
    "    4: {1: -2, 2: -2, 3: 0, 4: 0},\n",
    "    6: {1: -3, 2: -3, 3: 0, 4: 0},\n",
    "    8: {1: -4, 2: -4, 3: 0, 4: 0},\n",
    "}\n",
    "\n",
    "for gw in range(1, 39):\n",
    "    cs_column = f\"{gw}_0_goals\"\n",
    "    gc_1_column = f\"{gw}_1_goals\"\n",
    "    gc_2_column = f\"{gw}_2_goals\"\n",
    "    gc_4_column = f\"{gw}_4_goals\"\n",
    "    gc_6_column = f\"{gw}_6_goals\"\n",
    "    gc_8_column = f\"{gw}_8_goals\"\n",
    "\n",
    "    player_xp_cs[str(gw)] = player_xp_cs.apply(\n",
    "        lambda row: (\n",
    "            gc_probs.loc[\n",
    "                gc_probs[\"team_id\"] == row[\"team_id\"], cs_column\n",
    "            ].values[0]\n",
    "            * points_per_goal_scenario[0][row[\"element_type\"]]\n",
    "            + gc_probs.loc[\n",
    "                gc_probs[\"team_id\"] == row[\"team_id\"], gc_1_column\n",
    "            ].values[0]\n",
    "            * points_per_goal_scenario[1]\n",
    "            + gc_probs.loc[\n",
    "                gc_probs[\"team_id\"] == row[\"team_id\"], gc_2_column\n",
    "            ].values[0]\n",
    "            * points_per_goal_scenario[2][row[\"element_type\"]]\n",
    "            + gc_probs.loc[\n",
    "                gc_probs[\"team_id\"] == row[\"team_id\"], gc_4_column\n",
    "            ].values[0]\n",
    "            * points_per_goal_scenario[4][row[\"element_type\"]]\n",
    "            + gc_probs.loc[\n",
    "                gc_probs[\"team_id\"] == row[\"team_id\"], gc_6_column\n",
    "            ].values[0]\n",
    "            * points_per_goal_scenario[6][row[\"element_type\"]]\n",
    "            + gc_probs.loc[\n",
    "                gc_probs[\"team_id\"] == row[\"team_id\"], gc_8_column\n",
    "            ].values[0]\n",
    "            * points_per_goal_scenario[8][row[\"element_type\"]]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "player_xp_cs = player_xp_cs.round(2)\n",
    "\n",
    "xp_cs_1 = player_xp_cs[[\"Player\", \"1\"]]\n",
    "\n",
    "print(xp_cs_1.sort_values(by=\"1\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_xp_goals_prefixed columns: Index(['goals_fpl_id', 'goals_Player', 'goals_web_name', 'goals_Age',\n",
      "       'goals_team_name', 'goals_team_id', 'goals_element_type',\n",
      "       'goals_now_cost', 'goals_tsb', 'goals_Min', 'goals_90s',\n",
      "       'goals_finishing', 'goals_MP_new', 'goals_90s_new',\n",
      "       'goals_weighted_npxG', 'goals_1', 'goals_2', 'goals_3', 'goals_4',\n",
      "       'goals_5', 'goals_6', 'goals_7', 'goals_8', 'goals_9', 'goals_10',\n",
      "       'goals_11', 'goals_12', 'goals_13', 'goals_14', 'goals_15', 'goals_16',\n",
      "       'goals_17', 'goals_18', 'goals_19', 'goals_20', 'goals_21', 'goals_22',\n",
      "       'goals_23', 'goals_24', 'goals_25', 'goals_26', 'goals_27', 'goals_28',\n",
      "       'goals_29', 'goals_30', 'goals_31', 'goals_32', 'goals_33', 'goals_34',\n",
      "       'goals_35', 'goals_36', 'goals_37', 'goals_38'],\n",
      "      dtype='object')\n",
      "player_xp_goals_prefixed columns after renaming: Index(['fpl_id', 'Player', 'web_name', 'Age', 'team_name', 'team_id',\n",
      "       'element_type', 'now_cost', 'tsb', 'Min', '90s', 'MP_new', '90s_new',\n",
      "       'goals_90s_new', 'goals_weighted_npxG', 'goals_1', 'goals_2', 'goals_3',\n",
      "       'goals_4', 'goals_5', 'goals_6', 'goals_7', 'goals_8', 'goals_9',\n",
      "       'goals_10', 'goals_11', 'goals_12', 'goals_13', 'goals_14', 'goals_15',\n",
      "       'goals_16', 'goals_17', 'goals_18', 'goals_19', 'goals_20', 'goals_21',\n",
      "       'goals_22', 'goals_23', 'goals_24', 'goals_25', 'goals_26', 'goals_27',\n",
      "       'goals_28', 'goals_29', 'goals_30', 'goals_31', 'goals_32', 'goals_33',\n",
      "       'goals_34', 'goals_35', 'goals_36', 'goals_37', 'goals_38'],\n",
      "      dtype='object')\n",
      "                 Player  goals_1  pens_1  assists_1  cs_1\n",
      "593          Diogo Jota     3.39    0.00        NaN   NaN\n",
      "613       Mohamed Salah     3.22    0.47        NaN   NaN\n",
      "753      Alexander Isak     2.94    0.44        NaN   NaN\n",
      "591        Darwin Núñez     2.93    0.00        NaN   NaN\n",
      "657      Erling Haaland     2.68    0.26        NaN   NaN\n",
      "735       Harvey Barnes     2.51    0.00        NaN   NaN\n",
      "611           Luis Díaz     2.37    0.00        NaN   NaN\n",
      "488       Ali Al Hamadi     2.19    0.28        NaN   NaN\n",
      "697  Alejandro Garnacho     2.12    0.00        NaN   NaN\n",
      "949       Son Heung-min     2.12    0.37        NaN   NaN\n",
      "Player expected values for all metrics merged and saved successfully for gameweek 3.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Rename the columns to add prefixes\n",
    "player_xp_goals_prefixed = player_xp_goals.add_prefix('goals_')\n",
    "player_xp_pens_prefixed = player_xp_pens.add_prefix('pens_')\n",
    "player_xp_assists_prefixed = player_xp_assists.add_prefix('assists_')\n",
    "player_xp_cs_prefixed = player_xp_cs.add_prefix('cs_')\n",
    "\n",
    "# Step 2: Ensure 'Player' column is correctly renamed back\n",
    "for df in [player_xp_goals_prefixed, player_xp_pens_prefixed, player_xp_assists_prefixed, player_xp_cs_prefixed]:\n",
    "    df.rename(columns={\n",
    "        f\"{df.columns[0]}\": \"fpl_id\",\n",
    "        f\"{df.columns[1]}\": \"Player\",  # Ensuring Player column is correctly renamed\n",
    "        f\"{df.columns[2]}\": \"web_name\",\n",
    "        f\"{df.columns[3]}\": \"Age\",\n",
    "        f\"{df.columns[4]}\": \"team_name\",\n",
    "        f\"{df.columns[5]}\": \"team_id\",\n",
    "        f\"{df.columns[6]}\": \"element_type\",\n",
    "        f\"{df.columns[7]}\": \"now_cost\",\n",
    "        f\"{df.columns[8]}\": \"tsb\",\n",
    "        f\"{df.columns[9]}\": \"Min\",\n",
    "        f\"{df.columns[10]}\": \"90s\",\n",
    "        f\"{df.columns[11]}\": \"MP_new\",\n",
    "        f\"{df.columns[12]}\": \"90s_new\"\n",
    "    }, inplace=True)\n",
    "\n",
    "\n",
    "# Step 3: Remove rows with NaN values in the Player column in all relevant dataframes\n",
    "player_xp_goals_prefixed = player_xp_goals_prefixed.dropna(subset=[\"Player\"])\n",
    "player_xp_pens_prefixed = player_xp_pens_prefixed.dropna(subset=[\"Player\"])\n",
    "player_xp_assists_prefixed = player_xp_assists_prefixed.dropna(subset=[\"Player\"])\n",
    "player_xp_cs_prefixed = player_xp_cs_prefixed.dropna(subset=[\"Player\"])\n",
    "\n",
    "# Step 4: Merge the dataframes\n",
    "merged_df = player_xp_goals_prefixed.merge(player_xp_pens_prefixed, on=[\"fpl_id\", \"Player\", \"web_name\", \"Age\", \"team_name\", \"team_id\", \"element_type\", \"now_cost\", \"tsb\", \"Min\", \"90s\", \"MP_new\", \"90s_new\"], how='outer')\n",
    "merged_df = merged_df.merge(player_xp_assists_prefixed, on=[\"fpl_id\", \"Player\", \"web_name\", \"Age\", \"team_name\", \"team_id\", \"element_type\", \"now_cost\", \"tsb\", \"Min\", \"90s\", \"MP_new\", \"90s_new\"], how='outer')\n",
    "merged_df = merged_df.merge(player_xp_cs_prefixed, on=[\"fpl_id\", \"Player\", \"web_name\", \"Age\", \"team_name\", \"team_id\", \"element_type\", \"now_cost\", \"tsb\", \"Min\", \"90s\", \"MP_new\", \"90s_new\"], how='outer')\n",
    "\n",
    "# Step 5: Inspect the merged dataframe\n",
    "merged_1 = merged_df[[\"Player\", \"goals_1\", \"pens_1\", \"assists_1\", \"cs_1\"]]\n",
    "print(merged_1.sort_values(by=\"goals_1\", ascending=False).head(10))\n",
    "\n",
    "# Step 6: Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv(f\"C:/Users/erknud3/fpl-optimization/model/data/Prediction_Data/player_ev_gw{newest_gw}.csv\", index=False)\n",
    "\n",
    "print(f\"Player expected values for all metrics merged and saved successfully for gameweek {newest_gw}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fpl_id           Player  team_id\n",
      "0     134     James Milner        5\n",
      "1     344              NaN       13\n",
      "2     236  James Tarkowski        8\n",
      "3     238     Ashley Young        8\n",
      "4     414       John Ruddy       15\n",
      "   fpl_id           Player  team_id\n",
      "0     134     James Milner        5\n",
      "1     344              NaN       13\n",
      "2     236  James Tarkowski        8\n",
      "3     238     Ashley Young        8\n",
      "4     414       John Ruddy       15\n",
      "   fpl_id           Player  team_id\n",
      "0     134     James Milner        5\n",
      "1     344              NaN       13\n",
      "2     236  James Tarkowski        8\n",
      "3     238     Ashley Young        8\n",
      "4     414       John Ruddy       15\n",
      "   fpl_id           Player  team_id\n",
      "0     134     James Milner        5\n",
      "1     344              NaN       13\n",
      "2     236  James Tarkowski        8\n",
      "3     238     Ashley Young        8\n",
      "4     414       John Ruddy       15\n"
     ]
    }
   ],
   "source": [
    "# Inspect the key columns for consistency across all dataframes\n",
    "print(player_xp_goals_prefixed[[\"fpl_id\", \"Player\", \"team_id\"]].drop_duplicates().head())\n",
    "print(player_xp_pens_prefixed[[\"fpl_id\", \"Player\", \"team_id\"]].drop_duplicates().head())\n",
    "print(player_xp_assists_prefixed[[\"fpl_id\", \"Player\", \"team_id\"]].drop_duplicates().head())\n",
    "print(player_xp_cs_prefixed[[\"fpl_id\", \"Player\", \"team_id\"]].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
